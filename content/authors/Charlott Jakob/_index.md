---
# Display name
title: Charlott Jakob

# Full name (for SEO)
first_name: Charlott
last_name: Jakob

# Username (this should match the folder name)
authors:
  - Charlott Jakob

# Is this the primary user of the site?
superuser: false

# Role/position
role: PhD Candidate

# Organizations/Affiliations
organizations:
  - name: Technische Universität Berlin
    url: ''

# Short bio (displayed in user profile at end of posts)
bio: 
  - PhD Candidate

interests:
  - Natural Language Processing
  - Human-Computer Interaction
  - Algorithmic Bias
  - Explainability


# Social/Academic Networking
# For available icons, see: https://docs.hugoblox.com/getting-started/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "#contact" for contact widget.
social:
  - icon: envelope
    icon_pack: fas
    link: 'mailto:test@example.org'
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/GeorgeCushen
  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.co.uk/citations?user=sIwtMXoAAAAJ
  - icon: github
    icon_pack: fab
    link: https://github.com/gcushen
# Link to a PDF of your resume/CV from the About widget.
# To enable, copy your resume/CV to `static/files/cv.pdf` and uncomment the lines below.
# - icon: cv
#   icon_pack: ai
#   link: files/cv.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: ''

# Organizational groups that you belong to (for People widget)
#   Set this to `[]` or comment out if you are not using People widget.
user_groups:
  - Researchers
---
Charlott Jakob received her bachelor's degree in Industrial Engineering from the Karlsruhe Institute of Technology. She then pursued further studies in Industrial Engineering, majoring in Information & Communication Systems, at TU Berlin, where she completed her master’s thesis in the Quality and Usability Lab. Since 2023, she is employed as a research assistant in the XplaiNLP group in the QUL, exploring the interaction between NLP systems and humans towards responsible and ethical AI usage. Her focus is on uncovering discrimination due to algorithmic biases and examining machines’ transparency by applying explainability techniques.