---
title: 'ACL 2025: A Week of Innovation and Collaboration in NLP 🚀'
date: 2025-08-01
---

In July 2025, eight members of the XplaiNLP research group had the opportunity to attend the Annual Meeting of the Association for Computational Linguistics (ACL 2025) in Vienna. What began with great anticipation turned into a week filled with inspiring discussions, cutting-edge research insights, and valuable connection. 🎉

<!--more-->

We were inspired by the keynotes delivered by Verena Rieser, Isabelle Augenstein, Andreas Vlachos, Barbara Plank, Jean-Rémi King, and Luke Zettlemoyer, each of them offered valuable insights into the current and future directions of NLP, responsible AI, and how language is processed in the human brain.

Jing Yang, Veronika Solopova, Nils Feldhus, Max Upravitelev, Premtim S., Ariana Sahitaj, Qianli Wang and the research group lead Vera Schmitt presented multiple papers on a wide range of topics. Our group presented research on explainability methods for NLP models, approaches to disinformation narrative detection, and evaluation frameworks for model faithfulness. We particularly valued the vibrant discussions around interpretability, robustness, and human-centered evaluation—topics that lie at the core of our research agenda.

Link to papers: 
1. Findings: "FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation" https://aclanthology.org/2025.findings-acl.64/ 
2. 𝐅𝐄𝐕𝐄𝐑 𝐖𝐨𝐫𝐤𝐬𝐡𝐨𝐩: "Exploring Semantic Filtering Heuristics for Efficient Claim Verification" https://aclanthology.org/2025.fever-1.17/ 
3. 𝐍𝐋𝐏𝟒𝐏𝐨𝐬𝐢𝐭𝐢𝐯𝐞𝐈𝐦𝐩𝐚𝐜𝐭 𝐖𝐨𝐫𝐤𝐬𝐡𝐨𝐩: "Hybrid Annotation for Propaganda Detection: Integrating LLM Pre-Annotations with Human Intelligence" https://aclanthology.org/2025.nlp4pi-1.18/
4. 𝐔𝐍𝐋𝐏 𝐖𝐨𝐫𝐤𝐬𝐡𝐨𝐩: "Improving Sentiment Analysis for Ukrainian Social Media Code-Switching Data" https://aclanthology.org/2025.unlp-1.18/ 
5. 𝐒𝐜𝐡𝐨𝐥𝐚𝐫𝐥𝐲 𝐃𝐨𝐜𝐮𝐦𝐞𝐧𝐭 𝐏𝐫𝐨𝐜𝐞𝐬𝐬𝐢𝐧𝐠 𝐖𝐨𝐫𝐤𝐬𝐡𝐨𝐩: "Comparing LLMs and BERT-based Classifiers for Resource-Sensitive Claim Verification in Social Media" https://aclanthology.org/2025.sdp-1.26/

Inspired by the discussions at ACL, our team is now working on a follow-up study on narrative shifts in multimodal disinformation and expanding our evaluation frameworks for explainable AI. We’re also deepening collaborations with international partners we connected with in Vienna.
